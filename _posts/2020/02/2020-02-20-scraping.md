---
title: ウェブスクレイピング小手先の技ノート
tags: python scraping
---

習得した技法を本稿にまとめておく。

## Free Wi-Fi 禁止ドメインの判定

**問題**：某サイトでスクレイピングをしたい。
しかしそこはいかがわしいサイトであるので、Free Wi-Fi がブラックリストに入れている可能性がある。
それをあらかじめ知りたい。

**解**：そのようなサイトにブラウザーでアクセスすると、基本的には 403 エラーが戻ってくる。
そこで、次のようにしてトップページの HTTP status を得る：

```console
$bash wget --spider -S $URL 2>&1 | grep HTTP/ | awk '{print $2}'
```

さらに `grep 403` にパイプするなどの応用が考えられる。

## パーセント文字の混入した URL の取り扱い

**問題**：ブラウザーのアドレス欄やダウンロードした HTML ファイル中の
`<a>` タグや `<img>` タグの属性中などに含まれる文字列であって、正規表現でいうと
`(%[0-9A-F]{2})+` の形をしたテキストを読みたい。

または反対に、日本語で検索パターンを持っているときに、リクエストとしては
`(%[0-9A-F]{2})+` の形に変換したい。

**解**：Python 標準モジュールの `urilib.parse` にある関数
`unquote()`, `quote()` をそれぞれ用いる。

```python
>>> from urilib.parse import unquote, quote
>>> unquote('%E9%8E%A7')
'鎧'

>>> quote('パンツ')
'%E3%83%91%E3%83%B3%E3%83%84'
```
