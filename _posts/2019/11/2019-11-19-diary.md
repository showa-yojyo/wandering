---
title: 537 日目（雨のち晴れ）ヒエヒエ
mathjax: true
---

0:15 頃雨量が増す。あずまやの簾の屋根では厳しいので脱出。
雨に強いベンチのある糀谷駅が近いことを思い出して移動。靴がそろそろ換え時のようだ。

1:00 頃糀谷駅到着。期待のベンチを目指す。先客が寝ている。
別のベンチも同様。改札口シャッター前の柱の縁石に腰掛けて辞退が好転するのを待つ。

3:30 尿意を催したのでトイレを目指して移動する。
バス停横の地図を見て、トイレマークのある公園を調べて移動。

4:30 萩中くすのき公園（萩中一丁目？）に到着。雨が小康状態になっている。
用事を済ませてベンチを拭いて座って居眠り。幸い気温は低くない。

6:10 再起動。体が冷えていない。雑色へ移動。

6:50 松のや雑色店。玉子丼＋無料ポテサラ。
大荷物なのに窮屈な壁側カウンター席を選んでしまった。

食後、雑色駅前広場ベンチに移動。大田区議員の演説を耳にしながら居眠り。

8:45 再起動。図書館移動前恒例の買い出しに出る。

8:55 オーケーサガン店。

* サッポロポテトバーベキュー
* 牛乳入りパン
* 野菜ジュース

9:15 [大田区六郷図書館][ota-11]。機械学習の本と deep learning の本をとって二階キャレルに着席。

まず昨日の Wi-Fi 手続き変更対応だ。Ota_City_Free_Wi-Fi_1 の接続画面の手順が昔に戻ったと推測。
メールアドレスの登録からやり直し（これは昨日のうちに終わった）、画面遷移のコードを書き換える必要がある。

Deep learning の本を見つけたので興味本位で読み始める。Python なので思いの外興が乗る。
勢い余って本書のコードを `git clone` してしまう。

13:20 朝刊残り確認＆おやつ休憩。私の好きな東京新聞は当図書館ではカウンター預かりになっていると今知る。

13:55 キャレルに戻る。おやつを食いながら反芻していたラーニング本のわからない点を確認。
画像データの推論処理のあたりの記述に踏み込みが足りない（著者のせいにする）。

16:55 ラーニング本を置く。後半難しくて疲れた。今日はもう何も作れないし読めない。
Twitter で検索して遊ぶ。

18:50 退館。

19:15 オーケーサガン店。

* 野菜天重
* カットピザポテトツナコーン
* 豆大福

19:30 タイヤ公園。ベンチで晩飯。
この時間帯は高校生男子が必ずいるようだ。

20:10 ゲームズイモン。MJ プロ卓東風戦。このザマだ：

```text
11/19 -124.3(-12.43)
11/19の戦績
【SCORE】
合計SCORE:-124.3

【最終段位】
四人打ち段位:魔神 幻球:4

【11/19の最新8試合の履歴】
1st|--------
2nd|*--**---
3rd|-*---*--
4th|--*---**
old         new

【順位】
1位回数:1(10.00%)
2位回数:3(30.00%)
3位回数:2(20.00%)
4位回数:4(40.00%)
平均順位:2.90

プレイ局数:45局

【打ち筋】
アガリ率:17.78%(8/45)
平均アガリ翻:3.38翻
平均アガリ巡目:11.88巡
振込み率:17.78%(8/45)

【11/19の最高役】
最高役のデータがありません。最高役は、跳満以上のアガリが対象となります。
```

四人全員に各局好配牌という対局があった。私は東一局でピンフ 3900 点の手。
下家と対面が跳満 12000 点、上家はオーラスチートイ 1600 点だが、私を直撃すればラス目脱出という貴重なアガリ。
上家は最強神というレア段位の打ち手なのでシビアな手順にも迷いがない。

22:10 退店。とぼとぼと西六郷三丁目公園へ移動。23:00 休止状態。

## 読み物

* 朝刊（朝日、産経）
  * 産経抄の内容がザビエルから沢尻エリカ容疑者へというすごいものだ。
  * 谷亮子先生のインタビュー。掛け値なしに立派な人物であることがよくわかる。
* 斎藤康毅著『ゼロから作る Deep Learning』
  * NumPy のブロードキャストの説明がわかりやすい。こうすればいいのか。
  * Python で `AND`, `NAND`, `OR`, `XOR` をこの順に実装するのだが、この順序は適切だろうか。

    ```python
    def NAND(x1, x2):
        """Return NAND of x1 and x2"""

        x = np.array([x1, x2])
        weight = np.array([-.5, -.5])
        bias = .7
        return 1 if np.sum(weight * x) + bias > 0 else 0
    ```

    計算機科学的には `NAND` を実装して残りを `NAND` から組み立てるのが筋ではないだろうか。
    それとも deep learning 的な見地からはこれが正当なんだろうか。
  * 本書の階段関数の実装を暗記すること。潰しがきく。
  * シグモイド関数は曲線がタンジェント似ている（数式を見て少し考えれば理由がわかる）。
    * シグモイドの意味は「シグマの形の」くらいか。
  * ニューラルネットワークは活性化関数がキモのようだ。
  * 行列の乗法にこんなに紙幅を割いて……。
  * 関数 `softmax` の実装注意は良し。
  * 手書き数字認識のコードを実行するとかなりの時間がかかる。
    コードをアレンジしたときに実引数を間違えていた。要素を渡すべきところを配列を渡していた。
    NumPy のブロードキャストの罠だ。
  * `mean_squared_error` は `np.asarray` を使うべきだろう。

    ```python
    def mean_squared_error(y, t):
        a = np.asarray
        return .5 * np.sum((a(y) - a(t)) ** 2)
    ```

  * `cross_entropy_error` の $\log 0$ 対策はこんなんでいいのか。
  * 複数の同サイズ配列からランダムに同じ添字の要素を得る方法に NumPy の配列マスクを応用する。
  * 線形代数入門レベルや微分を知らない読者が存在するのか？
    存在するとしても、本文の説明で理解するか？
  * 勾配法。アルゴリズムの教科書で見た名前だ。ここで使われるのか。

[ota-11]: {% link _libraries/11-ota/11-rokugo.md %}
